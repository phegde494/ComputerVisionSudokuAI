{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f58c6d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ea304f",
   "metadata": {},
   "source": [
    "After importing the required libraries, we next load the MNIST data set to train our digit recognition model\n",
    "This dataset has thousands of 28x28 black and white digit images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7fbba8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "# Normalize pixel vals to doubles in range [0, 1]\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf644c01",
   "metadata": {},
   "source": [
    "Next, we define our digit recognition model to take in 28x28 pixel images\n",
    "The ReLU function optimizes the hidden layer while Softmax optimizes the output layer (good for multi-class classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e7931475",
   "metadata": {},
   "outputs": [],
   "source": [
    "digit_recognition_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f803c65a",
   "metadata": {},
   "source": [
    "Finally, we can train the model and save the final product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bea08454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1704 - accuracy: 0.9497\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0587 - accuracy: 0.9823\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0408 - accuracy: 0.9873\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0294 - accuracy: 0.9912\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0214 - accuracy: 0.9930\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0156 - accuracy: 0.9947\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 8s 5ms/step - loss: 0.0113 - accuracy: 0.9964\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0085 - accuracy: 0.9974\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0086 - accuracy: 0.9972\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0060 - accuracy: 0.9981\n",
      "313/313 [==============================] - 1s 1ms/step - loss: 0.0552 - accuracy: 0.9851\n",
      "Test Loss: 0.05519430711865425\n",
      "Test Accuracy: 0.9850999712944031\n",
      "(None, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# Train model \n",
    "digit_recognition_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 15 epochs is near ideal for MNIST dataset\n",
    "digit_recognition_model.fit(x_train, y_train, epochs=10)\n",
    "\n",
    "test_loss, test_accuracy = digit_recognition_model.evaluate(x_test, y_test)\n",
    "\n",
    "digit_recognition_model.save(\"trained_digit_model.h5\")\n",
    "\n",
    "print('Test Loss:', test_loss)\n",
    "print('Test Accuracy:', test_accuracy)\n",
    "print(digit_recognition_model.input_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ea16d5",
   "metadata": {},
   "source": [
    "Now, let's try running our model on the following example digit image:"
   ]
  },
  {
   "attachments": {
    "digit2.jpg": {
     "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCAAcABwBAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APn+vTPDHwP8TeJ9DtdXiuLCzt7kbo0uWcOU7NgKRgjkc81i+O/hvrPgW8xco1zp7ELHfIm1HYqCRjJIPUc9cHFcbSgEnABJ9BXaafH8Rrrw3NpdjBrkmjohLQLE/l7c5OOPUHgV6Fcw3um/sxXNt4hZo7qW5X7FDdLtlRfOU7QG5zgSH/dPpXhFel/Bzxj4a8H6vfzeILZy86ILe6WLzPI27i3HUZ+XkA9PQ16Pc/Hfw7pM91LaXusa20wDRxSQRQww9eAdob35DfWuNg+Ny67Dfab430SDUNLuQxjW2UK8BwcAZPPOPmyCOvPSvH6KKKK//9k="
    }
   },
   "cell_type": "markdown",
   "id": "9c732e81",
   "metadata": {},
   "source": [
    "![digit2.jpg](attachment:digit2.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fc49898d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "ex_img = cv2.imread('digit2.jpg')\n",
    "ex_img = cv2.cvtColor(ex_img, cv2.COLOR_BGR2GRAY)\n",
    "ex_img = ex_img.reshape(1, 28, 28)\n",
    "print (ex_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8fe2154f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 43ms/step\n",
      "[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "Classified digit is: 2\n"
     ]
    }
   ],
   "source": [
    "digit_probabilities = digit_recognition_model.predict(ex_img)\n",
    "\n",
    "print(digit_probabilities)\n",
    "\n",
    "digit = np.argmax(digit_probabilities)\n",
    "\n",
    "print(\"Classified digit is: \" + str(digit))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fdb59be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "ex_img2 = cv2.imread('num7.jpg')\n",
    "\n",
    "ex_img2 = cv2.cvtColor(ex_img2, cv2.COLOR_BGR2GRAY)\n",
    "ex_img2 = cv2.resize(ex_img2, (28, 28))\n",
    "ex_img2 = ex_img2.reshape(1, 28, 28)\n",
    "\n",
    "print (ex_img2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2d12ed83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 17ms/step\n",
      "[[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]]\n",
      "Classified digit is: 7\n"
     ]
    }
   ],
   "source": [
    "digit_probabilities2 = digit_recognition_model.predict(ex_img2)\n",
    "\n",
    "print(digit_probabilities2)\n",
    "\n",
    "digit2 = np.argmax(digit_probabilities2)\n",
    "\n",
    "print(\"Classified digit is: \" + str(digit2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a71d04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
