{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "46e238d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0d72ad",
   "metadata": {},
   "source": [
    "After importing the required libraries, we next load the MNIST data set to train our digit recognition model\n",
    "This dataset has thousands of 28x28 black and white digit images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "534d24c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "# Normalize pixel vals to doubles in range [0, 1]\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5dd021d",
   "metadata": {},
   "source": [
    "Next, we define our digit recognition model to take in 28x28 pixel images\n",
    "The ReLU function optimizes the hidden layer while Softmax optimizes the output layer (good for multi-class classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0d15754c",
   "metadata": {},
   "outputs": [],
   "source": [
    "digit_recognition_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41996af5",
   "metadata": {},
   "source": [
    "Finally, we can train the model and save the final product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3074d236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 9s 4ms/step - loss: 0.1694 - accuracy: 0.9504\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0600 - accuracy: 0.9816\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0397 - accuracy: 0.9874\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0286 - accuracy: 0.9911\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0203 - accuracy: 0.9937\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0148 - accuracy: 0.9954\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0120 - accuracy: 0.9960\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0095 - accuracy: 0.9969\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0071 - accuracy: 0.9976\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0065 - accuracy: 0.9979\n",
      "313/313 [==============================] - 1s 1ms/step - loss: 0.0646 - accuracy: 0.9852\n",
      "Test Loss: 0.06461824476718903\n",
      "Test Accuracy: 0.9851999878883362\n",
      "(None, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# Train model \n",
    "digit_recognition_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 15 epochs is near ideal for MNIST dataset\n",
    "digit_recognition_model.fit(x_train, y_train, epochs=10)\n",
    "\n",
    "test_loss, test_accuracy = digit_recognition_model.evaluate(x_test, y_test)\n",
    "\n",
    "digit_recognition_model.save(\"trained_digit_model.h5\")\n",
    "\n",
    "print('Test Loss:', test_loss)\n",
    "print('Test Accuracy:', test_accuracy)\n",
    "print(digit_recognition_model.input_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1d650b",
   "metadata": {},
   "source": [
    "Now, let's try running our model on the following example digit image:"
   ]
  },
  {
   "attachments": {
    "digit2.jpg": {
     "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCAAcABwBAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APn+vTPDHwP8TeJ9DtdXiuLCzt7kbo0uWcOU7NgKRgjkc81i+O/hvrPgW8xco1zp7ELHfIm1HYqCRjJIPUc9cHFcbSgEnABJ9BXaafH8Rrrw3NpdjBrkmjohLQLE/l7c5OOPUHgV6Fcw3um/sxXNt4hZo7qW5X7FDdLtlRfOU7QG5zgSH/dPpXhFel/Bzxj4a8H6vfzeILZy86ILe6WLzPI27i3HUZ+XkA9PQ16Pc/Hfw7pM91LaXusa20wDRxSQRQww9eAdob35DfWuNg+Ny67Dfab430SDUNLuQxjW2UK8BwcAZPPOPmyCOvPSvH6KKKK//9k="
    }
   },
   "cell_type": "markdown",
   "id": "463fa873",
   "metadata": {},
   "source": [
    "![digit2.jpg](attachment:digit2.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b73a00b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "ex_img = cv2.imread('digit2.jpg')\n",
    "ex_img = cv2.cvtColor(ex_img, cv2.COLOR_BGR2GRAY)\n",
    "ex_img = ex_img.reshape(1, 28, 28)\n",
    "print (ex_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d7536800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 20ms/step\n",
      "[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "Classified digit is: 2\n"
     ]
    }
   ],
   "source": [
    "digit_probabilities = digit_recognition_model.predict(ex_img)\n",
    "\n",
    "print(digit_probabilities)\n",
    "\n",
    "digit = np.argmax(digit_probabilities)\n",
    "\n",
    "print(\"Classified digit is: \" + str(digit))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "aa71d36b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "ex_img2 = cv2.imread('num7.jpg')\n",
    "\n",
    "ex_img2 = cv2.cvtColor(ex_img2, cv2.COLOR_BGR2GRAY)\n",
    "ex_img2 = cv2.resize(ex_img2, (28, 28))\n",
    "ex_img2 = ex_img2.reshape(1, 28, 28)\n",
    "\n",
    "print (ex_img2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "977fbdf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 17ms/step\n",
      "[[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]]\n",
      "Classified digit is: 7\n"
     ]
    }
   ],
   "source": [
    "digit_probabilities2 = digit_recognition_model.predict(ex_img2)\n",
    "\n",
    "print(digit_probabilities2)\n",
    "\n",
    "digit2 = np.argmax(digit_probabilities2)\n",
    "\n",
    "print(\"Classified digit is: \" + str(digit2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52cd707",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ec70f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
